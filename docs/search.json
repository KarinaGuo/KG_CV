[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Social Media Feed\n\n\n\n\n\n\n\noutreach\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2024\n\n\n\n\n\n\n  \n\n\n\n\nSo, what music do you like?\n\n\n\n\n\n\n\ncode\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2023\n\n\n\n\n\n\n  \n\n\n\n\nESA 2023\n\n\n\n\n\n\n\noutreach\n\n\n\n\n\n\n\n\n\n\n\nAug 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nProject on Machine Learning and Leaf Trait Pt. 2\n\n\n\n\n\n\n\ncode\n\n\nproject\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2023\n\n\n\n\n\n\n  \n\n\n\n\nProject on Machine Learning and Leaf Trait Pt. 1\n\n\n\n\n\n\n\ncode\n\n\nproject\n\n\n\n\n\n\n\n\n\n\n\nApr 24, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I smile when I hear my colleagues say “I discovered X.” That’s kind of like Columbus claiming to have discovered America. It was here all along, it’s just that he didn’t know it. Experiments are not about discovery but about listening and translating the knowledge of other beings. —Robin Wall Kimmerer"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\nUniversity of New South Wales (2019-2023)\nBacherlor’s of Advanced Science (Hons.) major in Ecology and minor in Chemistry\n\nFirst Class Honours in Ecology\nFaculty of Science Dean’s List (2021)\nUniversity Medal for Ecology (2023)\nWAM: 88.625 / GPA: 6.83\n\nCheltenham Girl’s High School (2012-2018)\n\nAll-round Achievers (2019)\nATAR: 98.05"
  },
  {
    "objectID": "about.html#current-occupation",
    "href": "about.html#current-occupation",
    "title": "About Me",
    "section": "Current Occupation",
    "text": "Current Occupation\n\n\nPhD Student (University of Sydney)\n(Feb 2024 - Current)\n\n\nAttended workshops of Clearer Writing, Peer Review\n\n\n\n\nBotanic Gardens of Sydney; Research Centre of Ecosystem Resilience (ReCER, BGSyd) (March 2022 - Current)\nTechnical Officer Biodiversity Genomics\n\n\nManipulation of genetic data for further analysis including variant calling and filtering.\nConducting GWAS on individuals of Melaleuca quinquenervia to discover loci that signify rust resistance. Using discovered loci for genomic prediction models.\nWet lab work on Lenwebbia sp & Gossia frangratissima for successful extraction of high molecular weight DNA full genome sequencing. Includes ability to safely work with liquid nitrogen, CTAB buffers, rare earth metal clean up, DNA purification and quantification through NanoDrop One & Agilent Tape.\nRefactoring of the genetics processing of DArT SNP data for the Restore and Renew (RnR) webtool. Involved version control using Git, containerising the RnR genetics workflow on Docker, multi-stage builds of workflow, supporting project development, and outreach. Showed proficiency in collaborating with other team members to enhance existing workflows and develop new features for future pathways of the tool.\nMyrtle rust (Austropuccinia psidii) inoculation and scoring of Plant Breeding Information to distinguish between susceptible and resistant individuals against the disease.\nManaging ~70,000 samples through databasing collection information, maintenance, and organisation of their storage. Processing of incoming material in preparation of new samples and vouchers.\nEngaging in field work trips to help gather genetic samples. Involves learning flora identification skills, scheduling appropriate accommodation, and following WHS protocols.\nRapid selection and preparation of samples to send to Diversity Arrays Technology (DArT) for genotyping\nOutreach at conferences for external points of collaboration across states of Australia and feedback on procedures and workflows"
  },
  {
    "objectID": "about.html#research-experience",
    "href": "about.html#research-experience",
    "title": "About Me",
    "section": "Research Experience",
    "text": "Research Experience\n\nPresentations\n\nEcological Society of Australia x Society for Conservation Biology 2022 (ESA-SCBO2022)\nSpeed Talk: Creating large datasets through automating the measurement of leaf traits from herbarium sheets of Eucalypts using machine learning (CNN)\nEcological Society of Australia 2023\nTalk: Restore and Renew, Provenancing for restoration based on genetics and climate\nLandcoast2Tops Landcare Talk\nTalk: Introduction to Myrtle rust and Project on M. quinquenervia\nFriends of Ivanhoe Botanic Gardens\nTalk: Introduction to Myrtle rust and Project on M. quinquenervia\n\n\n\nProjects\n\n\nDeciphering the genetic basis of Myrtle rust (Austropuccinia psidii) resistance in Melaleuca quinquenervia\n\n\nIterating through variations of filtering VCF files of whole genome sequenced individuals of Melaleuca quinquenervia\nConducting association studies between genotype and phenotype (Myrtle rust resistance) using Genome Wide Association Studies of the aforementioned whole genome sequenced individuals\nConducting phylogenetic analyses (IQ-TREE2 and Astral) using BUSCO IDs between broad leaf Melaleuca species.\nInferred patterns of population genetic variation using Principal Component Analysis, conStruct and SNMF.\nTested for introgression between Melaleuca spp. by performing ABBA BABA tests, implemented in DSuite\nEstimated the demographic history using SMC++\n\n\n\n\nHonours, Automating the Measurement of Leaf Traits from Herbarium Sheets of Eucalypts using Machine Learning. DOI: https://doi.org/10.32942/X2DG6F\n\n\nGained expertise in the field of machine learning (ML) and working with various coding languages including R, python, and BASH.\nDeveloped a novel and functional workflow using CNN ML models (instance segmentation & object classification) to expand existing eucalypt leaf trait data by 50-fold\nStatistical analysis of big data, a trait dataset of ~140,000 data points, to find trait-climate relationships and link them to phylogeny\nDemonstrated ability to lead project development through instigating discussions, creating protocols, research method and proposal writing\nLiterature study to ensure novelty and to link our findings into current academic landscape\nPresentations in explaining complex concepts in a simple and engaging manner with logical flow\n\n\n\n\nInternational Genetically Engineered Machine (iGEM) Competition (Team UNSW Protecc Coral)\n\n\nWorking as the team leader in the sub-group, Science Communication, as crucial section of a larger team of 15 individuals\nOrganising meetings and providing reports to other team leaders for cohesive group progression\nProduction of a virtual exhibition, contacting Indigenous and local individuals to gather opinions\nFacilitated collaboration between different iGEM teams and members of the general public\n\n\n\n\nOther projects:\n\n\nJason Bragg Machine Learning (ML) Project on Melaleuca sp. with the Royal Botanic Garden Sydney; Training artificial intelligence to analyse large-scale digital herbarium sheets to identify and measure leaf area, and class different reproductive structures in the Melaleuca leucadendra complex (Myrtaceae)\nImpact of Herbivore Assemblage on Vegetative Community in a Semi-arid Shrubland; Measuring different effects of grazing intensity and type on a plant community’s vegetative cover and diversity through Shannon diversity index\nThe Effect of Soil Type, Initial Moisture Level and Heat Treatments on a Soil System’s Water Repellency; Measuring water repellency on different soil types, under different moisture levels after different heat treatment\nAustralian Species and their Shifting Functional Traits in the Changing Climate; Measurement of tree height, basal trunk width, and SLA in Australian natives across NSW’s different climates"
  },
  {
    "objectID": "about.html#volunteer-work",
    "href": "about.html#volunteer-work",
    "title": "About Me",
    "section": "Volunteer Work",
    "text": "Volunteer Work\nBiodiversity Conservation Trust (2022)\n\nExperience in Biodiversity Assessment Method (BAM) and Rapid Vegetation Integrity (Rapid VI) Assessment to survey private land for the NSW Biodiversity Conservation\nInvestment Strategy (BCIS)\n\nDigitisation of the Herbarium of New South Wales (2019)\nParramatta Bushcare Volunteer (2018, 2022-2023)"
  },
  {
    "objectID": "about.html#past-work-experiences",
    "href": "about.html#past-work-experiences",
    "title": "About Me",
    "section": "Past Work Experiences",
    "text": "Past Work Experiences\n\n\nGro Urban Oasis: Castle Towers (February 2020 – March 2022)\nSales Assistant\n\n\nProactively working towards campaign development\nInteracting with customers to build a relationship and build a safe environment for respect\nDeveloping social skills and encouragement of open-mindedness in customers to new ideas\nUtilising a strong background knowledge on plant care and maintenance to advise customers and ensure upkeep of merchandise\nAccurately scanning large volumes of products to meet daily sale goals, and promoting seasonal deals and themes\n\n\n\n\nGloria Jeans Epping (December 2018 – February 2020)\nBarista/Waitress\n\n\nWell-developed social abilities include conflict mitigation, relationship building and team cooperativity\nAbility to multitask, utilising a number of equipment simultaneously to deliver goals on schedule\nAssisting co-workers to maximise workplace productivity and success"
  },
  {
    "objectID": "posts/ML-project-one/index.html",
    "href": "posts/ML-project-one/index.html",
    "title": "Project on Machine Learning and Leaf Trait Pt. 1",
    "section": "",
    "text": "This is Part 1 of 2, where I briefly go through how I made my machine learning models, and what they do\n\nTo look at the source code, feel free to check out my GitHub\n\n\n\nMy project involved three key parts:\n\nPrepare my data for training, validating, and testing my machine learning models\nMy two machine learning models were then created with the datasets\nI used my machine learning models to make my dataset which was analysed for trends\n\n\n\n\nFigure 1. Workflow of project\n\n\n\n \n\n\n\nTo build a good machine learning model, I needed a well-annotated training dataset to train, optimise and evaluate my model. In my case, this was done through manual annotation of herbarium sheets (archived pressed plant images). Manual annotation is essentially me telling the machine learning model what to ‘learn’, and looked like spending hours tracing the outlines of leaves on these sheets.\nThe annotated datasets were then divided into three sets: the training set, the validating set, and the testing set.\n\nTraining Set: Used to train the model by showing it what pixels represented a leaf on a herbarium sheet.\nValidating Set: Employed to optimise the model’s hyperparameters and ensure proper it generalises well on unseen data.\nTesting Set: Used to evaluate the model’s performance and accuracy\n\n \n\n\n\n\n\nThis first model I created was aimed to segment leaves from herbarium sheets; to create masks of the pixels that represent each individual leaf, as in This process involved a cycle of optimisation. First, feed in the training and validating dataset with initial training parameters. These parameters shaped how the model learnt. Then, evaluate the quality of the first iteration of the model.\nThis step involved both qualitative and quantitative metrics. Qualitative metrics were looking at all the predicted herbarium sheets, like in Figure 2, and judging how it went. Did it do poorly on small leaves? Worse on broken leaves? And, so forth. Using these metrics I judged what needed to be amended in the training dataset for the next iteration. Similarly, quantitative metrics involved calculating values such as Precision, Recall, and F1-score which are measures of true positives, false negatives, etc. that are standardised in the machine learning field. From these metrics, I then changed the training dataset the model needed to improve it for the next iteration.\nOnce I’ve done more painstaking labelling of the training dataset, and tweaked the training parameters, I embarked the model on the second iteration. Training a brand new model and conducting the evaluation metrics again. I kept repeating this cycle until I was satisfied with the quality of the model.\n\n\n\nFigure 2. Predicted herbarium sheet, each colour is a separate leaf mask\n\n\n\n \n\n\n\n\nTo enhance the quality and accuracy of my workflow, I then developed a leaf classifier model. This model acted as an additional layer of filtration, classifying the output of the segmentation model into valid and invalid leaves.\nUsing the segmented leaf images generated by the first model, I manually annotated the images to create the necessary datasets for training, validating, and testing the leaf classifier model. Here, manual annotation involved me categorising leaf images generated by the first model as valid and invalid leaves. Then, like before, separating those images into the three datasets.\nOnce again, the creation of this model involved optimisation. Iterations of this machine learning model was crucial in ensuring the model was of apt quality and could accurately identify valid leaves.\n\nFigure 3. Example of valid and invalid leaf\n\n\n\n\n\n\n\nValid leaf\n\nInvalid leaf\n\n\n\n\n \n\n\n\n\nAfter being satisfied with both models, I applied them to the remaining herbarium images. This process generated a massive dataset, comprising of approximately 130,000 data points. The size of this dataset was 50 times larger than the previous datasets. This gave me an amazing framework where I could ask so many more questions during the analysis. It greatly expanded the sampling done at both a taxonomic level (inter- and intra- specific sampling), and at a spatial scale across Australia, to a degree not done before.\n\n \n\n\n\n\nThe final step in my project involved analysing the massive dataset created by the machine learning models. This dataset contained detailed information about the leaves, including their leaf area, leaf curvature and the size of the largest in-circle. As each herbarium sheet had their collection latitude and longitude I could then map it to climate, and see how the leaf traits changed across various variables. Furthermore, with their indepth taxonomic sampling, for the first time in literature, I explored how the leaf trait varied across the eucalypt taxonomy.\nFor a detailed analysis of the trends and patterns discovered in the dataset, check out my next blog post, where I share my novel findings and pretty graphs."
  },
  {
    "objectID": "posts/social-outreach/index.html",
    "href": "posts/social-outreach/index.html",
    "title": "Social Media Feed",
    "section": "",
    "text": "This is an embedded output of all my tweets, posts, and whatnot. Occasionally I’ll cross post so I’ve just added the most appropriate outreach method of the content\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView this post on Instagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA post shared by @crunchy_dandelion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView this post on Instagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA post shared by @crunchy_dandelion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView this post on Instagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA post shared by @crunchy_dandelion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView this post on Instagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA post shared by @crunchy_dandelion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView this post on Instagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA post shared by @crunchy_dandelion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView this post on Instagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA post shared by @crunchy_dandelion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView this post on Instagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA post shared by @crunchy_dandelion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView this post on Instagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA post shared by @crunchy_dandelion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView this post on Instagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA post shared by @crunchy_dandelion\n\n\n\n\n\n\nThank you to everyone who supported my journey through my undergraduate. I could list them as friends, family, supervisors, and whatnot. But at this point, the lines have blurred, friends have become as close as family, and supervisors to friends pic.twitter.com/ISa3W6PD8a\n\n— Karina Guo (she/her) (@dandy_gumnut) August 27, 2023\n\n\n\n\n\n\nLoved the networking and tours at @AustralianBG. Did y’all know they use medical x-rays to check seed viability.Thank you for this amazing mini-conference between @EERC_UNSW @BotanicSydney and @NSWDPE! pic.twitter.com/XVKxn83g8N\n\n— Karina Guo (she/her) (@dandy_gumnut) August 24, 2023\n\n\n\n\nAny entomologically well versed people know what #insect I’m seeing here on this Syncarpia? Heard it’s a gall mites of some sort pic.twitter.com/91wHZRIaRO\n\n— Karina Guo (she/her) (@dandy_gumnut) July 22, 2023\n\n\n\n\nAmazing symposium on weeds and genetics. Who knew the Lantana complex was made of ~20 species of varying morphology and aggressiveness?? Everyone always only talks about it being L. camara! 🏵️ @p_luirving pic.twitter.com/z01PApko7z\n\n— Karina Guo (she/her) (@dandy_gumnut) July 14, 2023\n\n\n\n\n\n::: {style=” display: flex; flex-direction: row; align-items: center;“} ::: {style=”background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 40px; margin-right: 14px; width: 40px;“}\n\n\n::: {style=” background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 100px;“}\n\n::: {style=” background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 60px;“} ::: ::: :::\n\n\n\n\n\n\n\n\n\n::: {style=” color:#3897f0; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:550; line-height:18px;“} View this post on Instagram\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {style=” background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 20px; width: 20px;“}\n\n::: {style=” width: 0; height: 0; border-top: 2px solid transparent; border-left: 6px solid #f4f4f4; border-bottom: 2px solid transparent; transform: translateX(16px) translateY(-4px) rotate(30deg)“}\n\n:::\n\n::: {style=” width: 0px; border-top: 8px solid #F4F4F4; border-right: 8px solid transparent; transform: translateY(16px);“}\n\n::: {style=” background-color: #F4F4F4; flex-grow: 0; height: 12px; width: 16px; transform: translateY(-4px);“} :::\n::: {style=” width: 0; height: 0; border-top: 8px solid #F4F4F4; border-left: 8px solid transparent; transform: translateY(-4px) translateX(8px);“} ::: ::: :::\n\n::: {style=” background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 224px;“}\n\n::: {style=” background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 144px;“} ::: :::\n\n\nA post shared by @crunchy_dandelion\n\n:::\n\n\n\n\nAmazing talks yesterday in the genomics symposium from amazing new people I’ve met! @terngirl @DrErinne pic.twitter.com/TGSBtGIKq6\n\n— Karina Guo (she/her) (@dandy_gumnut) July 6, 2023\n\n\n\n\nThanks for having me and helping us spread the word about restore and renew to those who need it! #ESAus23 @EcolSocAus pic.twitter.com/xn9YxM2emK\n\n— Karina Guo (she/her) (@dandy_gumnut) July 5, 2023\n\n\n\n\n1/ I’m in Darwin for the first time! I’ll be at #ESAus2023 talking about our Restore and Renew webtool project. It’s a project to boost the quality of restoration projects in NSW. Want to know more about it? Or check it out yourself here, https://t.co/Nn3qiT8yA8 pic.twitter.com/jqLYj7gWtj\n\n— Karina Guo (she/her) (@dandy_gumnut) July 2, 2023\n\n\n\n\n\n::: {style=” display: flex; flex-direction: row; align-items: center;“} ::: {style=”background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 40px; margin-right: 14px; width: 40px;“}\n\n\n::: {style=” background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 100px;“}\n\n::: {style=” background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 60px;“} ::: ::: :::\n\n\n\n\n\n\n\n\n\n::: {style=” color:#3897f0; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:550; line-height:18px;“} View this post on Instagram\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {style=” background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 20px; width: 20px;“}\n\n::: {style=” width: 0; height: 0; border-top: 2px solid transparent; border-left: 6px solid #f4f4f4; border-bottom: 2px solid transparent; transform: translateX(16px) translateY(-4px) rotate(30deg)“}\n\n:::\n\n::: {style=” width: 0px; border-top: 8px solid #F4F4F4; border-right: 8px solid transparent; transform: translateY(16px);“}\n\n::: {style=” background-color: #F4F4F4; flex-grow: 0; height: 12px; width: 16px; transform: translateY(-4px);“} :::\n::: {style=” width: 0; height: 0; border-top: 8px solid #F4F4F4; border-left: 8px solid transparent; transform: translateY(-4px) translateX(8px);“} ::: ::: :::\n\n::: {style=” background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 224px;“}\n\n::: {style=” background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 144px;“} ::: :::\n\n\nA post shared by @crunchy_dandelion\n\n:::\n\n\n\n\nOur leaf masking model isn’t perfect… That’s why we got another model (a leaf classifier) to flag these leaves as ‘invalid’. That allowed us to get rid of those pesky half leaves, and increasing our workflow’s accuracy! pic.twitter.com/ZnRHCkMAVH\n\n— Karina Guo (she/her) (@dandy_gumnut) July 2, 2023\n\n\n\n\nHere’s what my machine learning model does. It finds the pixels of leaves on the herbarium sheets. This saves me from having to measure it’s leaf by hand, one by one. In turn, I get a massive dataset (50x the size of original datasets!). pic.twitter.com/ooubsMXenV\n\n— Karina Guo (she/her) (@dandy_gumnut) June 30, 2023"
  },
  {
    "objectID": "posts/ML-project-two/index.html",
    "href": "posts/ML-project-two/index.html",
    "title": "Project on Machine Learning and Leaf Trait Pt. 2",
    "section": "",
    "text": "This is Part 2 of 2, here I analyse my dataset from the last part to explore two key questions\n\nTo look at the source code, feel free to check out my GitHub\n\n\n \n\n\n\n\nProject explored how leaf traits shift across the Australian climate and how phylogeny shaped leaf traits\nFound that leaf area was positively associated with mean annual precipitation\nSaw a strong variation in the trait-climate relationship was seen within species\nFrom the shallowest depths of this phylogeny to the deepest, i.e. from species to genera, there was an overall increase in the mean slope of the association between leaf area and precipitation\nSaw was at ~8.5 MYA there was a rapid convergence to the overall slope hypothesised to be due to gene flow ceasing\n\n\n \n\n\n\n\nIn this part of my project I wanted to see how the leaf trait changed across 1. Climate and 2. Phylogeny. Like mentioned in my last post, I could investigate how the trait changed in congruence with each other because of the site of the dataset.\n\nIn summary, the questions and hypothesise I proposed prior to the project were:\n\nHow do leaf traits shift across the Australian climate?\nI hypothesise that leaf area and largest in-circle area will correlate positively with mean annual precipitation and temperature\nTo what extent does phylogeny shape leaf traits?\nI hypothesise that gene flow will resolve in large trait variability at a shallow phylogenetic level (within species), which will gradually resolve to a trait-climate relationship at deeper levels (for example, among species).\n\n\n \n\n\n\n\nTo really understand why I was asking these questions, a bit of context is needed.\nFirstly, leaf area. As many of you readers are probably well aware of, leaves are the fundamental units of photosynthesis. And because of this, they have a vast range of impacts at different levels of scales. From affecting the carbon cycle around the globe, to influencing species interaction at an individual level. Therefore, as a better understanding of leaf trait variation can result in better predictions and models.\nWe know that, leaf traits, such as leaf area, are tied to their environment. This may come in the form of a constraint, where a climatic variable may result in the trait being no bigger or smaller than a certain size (e.g., see Wright et al. 2017, Guo et al. 2000, Cornelissen 1999). For instance, leaf area has been found to increase from dry to wet environments and from colder to hotter climates. And this may have been due to leaf area being linked to thermal regulation. Where a more effective thermal regulation and reduced water loss is found in leaves that are smaller, particularly those that are more narrow. However, this trend isn’t always this simple and can vary at a geographic and taxonomic scale. As such, my study, for the first time, looks at this trend within every species of eucalypts (Angohphora, Corymbia, Eucalyptus) in detail for all of Australia. In particular I looked at eucalypt leaf traits of Australia, and how they varied against mean annual precipitation and climate\nBut what I found more interesting in this study was looking at this how evolutionary history played an influence on the relationship between trait and climate. As such, I aimed to investigate how this trait-climate trend changed within and across different phylogenetic classifications, such as species, subgenera and genera. Existing literature acknowledges that phylogeny and contemporary demography, including intraspecific gene flow, may result in this trait-climate trend within species being weaker, unrelated, or even following opposite directions to that reported among species. For example, gene flow between two populations may hinder the adaptation of leaf traits to their local environment, causing the trait-climate trend to diverge from the expected trend. On top of this, an individual’s evolutionary history may constrain phenotype and local adaptive capacity. However, current literature is unable to fully understanding these factors, possibly due to the limitations of current datasets generated using traditional methods.\nMy study places itself in a unique position with its use of the machine learning models detailed previously. With its application, I was able to create a comprehensive dataset that spans various taxonomic levels across Australia. By pairing this dataset with a fully resolved phylogenetic tree (Thornhill et al. 2019), I could link microevolution to macroevolution, and ask the questions I posed prior.\n\n\n\n\n\n\n\n\nNote: As a preface, the following sections will focus on how leaf area varied against mean annual precipitation as that were the most interesting findings of all traits and climatic variables.\n\n \n\n\n\n\nWe found that leaf area was positively associated with mean annual precipitation. This aligned to what was found in other studies of eucalypts. However, when compared to a study that looked at all taxa globally, we saw that eucalypts had a weaker and shallower slope.\n\n\n\n\n\n\n\n\n\n\n\n\nWhen then looked at how evolutionary history impacted the trait-climate relationship, i.e. the slope of our models. We saw that when we took a mean value within species, this resulted in the slope being greater and better reflected those of other studies (Falster et al. 2021, Wright et al. 2017). However, when species was added as a random effect we saw the opposite, a smaller slope. In essence, this meant that a strong variation in the trait-climate relationship was seen within species. A similar analysis was then done at different phylogenetic classifications including subgenera and genera. When looking at subgenera, we got the mean trait value within each slope and used that to see how the leaf trait changed against precipitation. And, as a result, we saw a dramatically greater slope (closer to that of other analyses), than in comparison to the species level. Likewise at the genera level, we also saw a greater slope, though less significantly than subgenera. In summary, from the shallowest depths of this phylogeny to the deepest, i.e. from species to genera, there was an overall increase in the mean slope of the association between leaf area and precipitation.\nFurthermore, our machine learning method also allowed us to look at this model throughout the whole span of time of the phylogeny. We know that the average trait-climate slope of species is roughly at 0.2, and that the overall slope of eucalypts is 0.4 (i.e. no grouping). However, current literature is unable to answer what happens at these two points? Well this is where my massive dataset comes in. Using Thornhill’s resolved phylogenetic tree, we separated the entire age of the tree into 20 separate intervals. At each time interval, tips that had split prior to the point were kept as individual unique lineages, while those that had split after the time interval was merged by common ancestry into a single ‘lineage’. For instance, the 1st interval was at 0 million years ago and included every tip of the tree as a lineage (418 lineages). Whereas, at the 3rd interval, 8.57 million years ago, 77 lineages were present. Running the statistical model at each lineage, and generating the overall slope. We then generate the following graph. And what we saw was at ~8.5 MYA there was a rapid convergence to the overall slope (akin to the species to subgenera separation mentioned prior). In which, I hypothesised to be due to gene flow. Where, at this point, gene flow ceases and we see that rapid convergence of the slope to the genus level.\n\n\n\nThe phylogenetic tree was split at 20 intervals at evenly spaced time periods. The mean slope within the lineages at each time point was calculated. For example, 0 MY had each species as a random effect, whereas 55 MY had two groups of species, corresponding to the deepest branch among the eucalypts. A convergence towards an approximate average slope was observed roughly 8.5 MY."
  },
  {
    "objectID": "posts/ML-project-two/index.html#using-machine-learning-to-link-climate-phylogeny-and-leaf-area-in-eucalypts-through-a-50-fold-expansion-of-current-leaf-trait-datasets-part-2",
    "href": "posts/ML-project-two/index.html#using-machine-learning-to-link-climate-phylogeny-and-leaf-area-in-eucalypts-through-a-50-fold-expansion-of-current-leaf-trait-datasets-part-2",
    "title": "Project on Machine Learning and Leaf Trait Pt. 2",
    "section": "",
    "text": "This is Part 2 of 2, here I analyse my dataset from the last part to explore two key questions\n\nTo look at the source code, feel free to check out my GitHub\n\n\n \n\n\n\n\nProject explored how leaf traits shift across the Australian climate and how phylogeny shaped leaf traits\nFound that leaf area was positively associated with mean annual precipitation\nSaw a strong variation in the trait-climate relationship was seen within species\nFrom the shallowest depths of this phylogeny to the deepest, i.e. from species to genera, there was an overall increase in the mean slope of the association between leaf area and precipitation\nSaw was at ~8.5 MYA there was a rapid convergence to the overall slope hypothesised to be due to gene flow ceasing\n\n\n \n\n\n\n\nIn this part of my project I wanted to see how the leaf trait changed across 1. Climate and 2. Phylogeny. Like mentioned in my last post, I could investigate how the trait changed in congruence with each other because of the site of the dataset.\n\nIn summary, the questions and hypothesise I proposed prior to the project were:\n\nHow do leaf traits shift across the Australian climate?\nI hypothesise that leaf area and largest in-circle area will correlate positively with mean annual precipitation and temperature\nTo what extent does phylogeny shape leaf traits?\nI hypothesise that gene flow will resolve in large trait variability at a shallow phylogenetic level (within species), which will gradually resolve to a trait-climate relationship at deeper levels (for example, among species).\n\n\n \n\n\n\n\nTo really understand why I was asking these questions, a bit of context is needed.\nFirstly, leaf area. As many of you readers are probably well aware of, leaves are the fundamental units of photosynthesis. And because of this, they have a vast range of impacts at different levels of scales. From affecting the carbon cycle around the globe, to influencing species interaction at an individual level. Therefore, as a better understanding of leaf trait variation can result in better predictions and models.\nWe know that, leaf traits, such as leaf area, are tied to their environment. This may come in the form of a constraint, where a climatic variable may result in the trait being no bigger or smaller than a certain size (e.g., see Wright et al. 2017, Guo et al. 2000, Cornelissen 1999). For instance, leaf area has been found to increase from dry to wet environments and from colder to hotter climates. And this may have been due to leaf area being linked to thermal regulation. Where a more effective thermal regulation and reduced water loss is found in leaves that are smaller, particularly those that are more narrow. However, this trend isn’t always this simple and can vary at a geographic and taxonomic scale. As such, my study, for the first time, looks at this trend within every species of eucalypts (Angohphora, Corymbia, Eucalyptus) in detail for all of Australia. In particular I looked at eucalypt leaf traits of Australia, and how they varied against mean annual precipitation and climate\nBut what I found more interesting in this study was looking at this how evolutionary history played an influence on the relationship between trait and climate. As such, I aimed to investigate how this trait-climate trend changed within and across different phylogenetic classifications, such as species, subgenera and genera. Existing literature acknowledges that phylogeny and contemporary demography, including intraspecific gene flow, may result in this trait-climate trend within species being weaker, unrelated, or even following opposite directions to that reported among species. For example, gene flow between two populations may hinder the adaptation of leaf traits to their local environment, causing the trait-climate trend to diverge from the expected trend. On top of this, an individual’s evolutionary history may constrain phenotype and local adaptive capacity. However, current literature is unable to fully understanding these factors, possibly due to the limitations of current datasets generated using traditional methods.\nMy study places itself in a unique position with its use of the machine learning models detailed previously. With its application, I was able to create a comprehensive dataset that spans various taxonomic levels across Australia. By pairing this dataset with a fully resolved phylogenetic tree (Thornhill et al. 2019), I could link microevolution to macroevolution, and ask the questions I posed prior.\n\n\n\n\n\n\n\n\nNote: As a preface, the following sections will focus on how leaf area varied against mean annual precipitation as that were the most interesting findings of all traits and climatic variables.\n\n \n\n\n\n\nWe found that leaf area was positively associated with mean annual precipitation. This aligned to what was found in other studies of eucalypts. However, when compared to a study that looked at all taxa globally, we saw that eucalypts had a weaker and shallower slope.\n\n\n\n\n\n\n\n\n\n\n\n\nWhen then looked at how evolutionary history impacted the trait-climate relationship, i.e. the slope of our models. We saw that when we took a mean value within species, this resulted in the slope being greater and better reflected those of other studies (Falster et al. 2021, Wright et al. 2017). However, when species was added as a random effect we saw the opposite, a smaller slope. In essence, this meant that a strong variation in the trait-climate relationship was seen within species. A similar analysis was then done at different phylogenetic classifications including subgenera and genera. When looking at subgenera, we got the mean trait value within each slope and used that to see how the leaf trait changed against precipitation. And, as a result, we saw a dramatically greater slope (closer to that of other analyses), than in comparison to the species level. Likewise at the genera level, we also saw a greater slope, though less significantly than subgenera. In summary, from the shallowest depths of this phylogeny to the deepest, i.e. from species to genera, there was an overall increase in the mean slope of the association between leaf area and precipitation.\nFurthermore, our machine learning method also allowed us to look at this model throughout the whole span of time of the phylogeny. We know that the average trait-climate slope of species is roughly at 0.2, and that the overall slope of eucalypts is 0.4 (i.e. no grouping). However, current literature is unable to answer what happens at these two points? Well this is where my massive dataset comes in. Using Thornhill’s resolved phylogenetic tree, we separated the entire age of the tree into 20 separate intervals. At each time interval, tips that had split prior to the point were kept as individual unique lineages, while those that had split after the time interval was merged by common ancestry into a single ‘lineage’. For instance, the 1st interval was at 0 million years ago and included every tip of the tree as a lineage (418 lineages). Whereas, at the 3rd interval, 8.57 million years ago, 77 lineages were present. Running the statistical model at each lineage, and generating the overall slope. We then generate the following graph. And what we saw was at ~8.5 MYA there was a rapid convergence to the overall slope (akin to the species to subgenera separation mentioned prior). In which, I hypothesised to be due to gene flow. Where, at this point, gene flow ceases and we see that rapid convergence of the slope to the genus level.\n\n\n\nThe phylogenetic tree was split at 20 intervals at evenly spaced time periods. The mean slope within the lineages at each time point was calculated. For example, 0 MY had each species as a random effect, whereas 55 MY had two groups of species, corresponding to the deepest branch among the eucalypts. A convergence towards an approximate average slope was observed roughly 8.5 MY."
  },
  {
    "objectID": "posts/ML-project-one/index.html#using-machine-learning-to-link-climate-phylogeny-and-leaf-area-in-eucalypts-through-a-50-fold-expansion-of-current-leaf-trait-datasets-part-1",
    "href": "posts/ML-project-one/index.html#using-machine-learning-to-link-climate-phylogeny-and-leaf-area-in-eucalypts-through-a-50-fold-expansion-of-current-leaf-trait-datasets-part-1",
    "title": "Project on Machine Learning and Leaf Trait Pt. 1",
    "section": "",
    "text": "This is Part 1 of 2, where I briefly go through how I made my machine learning models, and what they do\n\nTo look at the source code, feel free to check out my GitHub\n\n\n\nMy project involved three key parts:\n\nPrepare my data for training, validating, and testing my machine learning models\nMy two machine learning models were then created with the datasets\nI used my machine learning models to make my dataset which was analysed for trends\n\n\n\n\nFigure 1. Workflow of project\n\n\n\n \n\n\n\nTo build a good machine learning model, I needed a well-annotated training dataset to train, optimise and evaluate my model. In my case, this was done through manual annotation of herbarium sheets (archived pressed plant images). Manual annotation is essentially me telling the machine learning model what to ‘learn’, and looked like spending hours tracing the outlines of leaves on these sheets.\nThe annotated datasets were then divided into three sets: the training set, the validating set, and the testing set.\n\nTraining Set: Used to train the model by showing it what pixels represented a leaf on a herbarium sheet.\nValidating Set: Employed to optimise the model’s hyperparameters and ensure proper it generalises well on unseen data.\nTesting Set: Used to evaluate the model’s performance and accuracy\n\n \n\n\n\n\n\nThis first model I created was aimed to segment leaves from herbarium sheets; to create masks of the pixels that represent each individual leaf, as in This process involved a cycle of optimisation. First, feed in the training and validating dataset with initial training parameters. These parameters shaped how the model learnt. Then, evaluate the quality of the first iteration of the model.\nThis step involved both qualitative and quantitative metrics. Qualitative metrics were looking at all the predicted herbarium sheets, like in Figure 2, and judging how it went. Did it do poorly on small leaves? Worse on broken leaves? And, so forth. Using these metrics I judged what needed to be amended in the training dataset for the next iteration. Similarly, quantitative metrics involved calculating values such as Precision, Recall, and F1-score which are measures of true positives, false negatives, etc. that are standardised in the machine learning field. From these metrics, I then changed the training dataset the model needed to improve it for the next iteration.\nOnce I’ve done more painstaking labelling of the training dataset, and tweaked the training parameters, I embarked the model on the second iteration. Training a brand new model and conducting the evaluation metrics again. I kept repeating this cycle until I was satisfied with the quality of the model.\n\n\n\nFigure 2. Predicted herbarium sheet, each colour is a separate leaf mask\n\n\n\n \n\n\n\n\nTo enhance the quality and accuracy of my workflow, I then developed a leaf classifier model. This model acted as an additional layer of filtration, classifying the output of the segmentation model into valid and invalid leaves.\nUsing the segmented leaf images generated by the first model, I manually annotated the images to create the necessary datasets for training, validating, and testing the leaf classifier model. Here, manual annotation involved me categorising leaf images generated by the first model as valid and invalid leaves. Then, like before, separating those images into the three datasets.\nOnce again, the creation of this model involved optimisation. Iterations of this machine learning model was crucial in ensuring the model was of apt quality and could accurately identify valid leaves.\n\nFigure 3. Example of valid and invalid leaf\n\n\n\n\n\n\n\nValid leaf\n\nInvalid leaf\n\n\n\n\n \n\n\n\n\nAfter being satisfied with both models, I applied them to the remaining herbarium images. This process generated a massive dataset, comprising of approximately 130,000 data points. The size of this dataset was 50 times larger than the previous datasets. This gave me an amazing framework where I could ask so many more questions during the analysis. It greatly expanded the sampling done at both a taxonomic level (inter- and intra- specific sampling), and at a spatial scale across Australia, to a degree not done before.\n\n \n\n\n\n\nThe final step in my project involved analysing the massive dataset created by the machine learning models. This dataset contained detailed information about the leaves, including their leaf area, leaf curvature and the size of the largest in-circle. As each herbarium sheet had their collection latitude and longitude I could then map it to climate, and see how the leaf traits changed across various variables. Furthermore, with their indepth taxonomic sampling, for the first time in literature, I explored how the leaf trait varied across the eucalypt taxonomy.\nFor a detailed analysis of the trends and patterns discovered in the dataset, check out my next blog post, where I share my novel findings and pretty graphs."
  },
  {
    "objectID": "about.html#volunteer-work-student-activities",
    "href": "about.html#volunteer-work-student-activities",
    "title": "About Me",
    "section": "Volunteer Work & Student Activities",
    "text": "Volunteer Work & Student Activities\nBiodiversity Conservation Trust (2022)\n\nExperience in Biodiversity Assessment Method (BAM) and Rapid Vegetation Integrity (Rapid VI) Assessment to survey private land for the NSW Biodiversity Conservation\nInvestment Strategy (BCIS)\n\nDigitisation of the Herbarium of New South Wales (2019)\nParramatta Bushcare Volunteer (2018, 2022-2023)\nTalented Student Program (TSP) at UNSW\n\nParticipated in a range of different workshops that focused on developing skills surrounding leadership, academia, networking, and presentations"
  },
  {
    "objectID": "posts/spotify/index.html",
    "href": "posts/spotify/index.html",
    "title": "So, what music do you like?",
    "section": "",
    "text": "Set up\nI once got asked what music did I like. An admittedly, common small talk question that definitely has popped up more than once in life. But like every other time it’s been asked, I’ve never known how to answer it. So hey, why not interrogate Spotify to see some answers? Here, I’ve included the code and steps needed to get similar outputs to what I have here.\nYou’ll have to first request your data from Spotify. To do this go to Spotify on the web. Press on your profile picture -&gt; Account -&gt; Privacy Settings -&gt; Scroll down, tick the boxes you want and your data will come in your email when it’s ready. Note that your extended streaming history may take a week or more to come.\nOnce downloaded, you’ll want to set up a unique API that links to your account. Basically giving you a way to access their database. To do that you need to make a Spotify Developer account, that will let you set up a project that will have your ‘Client_ID’ and your ‘Client_Secret’. Here’s the official page to help get that set up for you. Note when the page prompts you to put in a callback URL, a good default is inputting a ‘localhost’ e.g., http://localhost:1410/“. This simply redirects output onto your personal device’s browser.\n# Setting up API tokens\nSys.setenv (SPOTIFY_CLIENT_ID = 'xxx')\nSys.setenv (SPOTIFY_CLIENT_SECRET = 'xxx')\nNext, we want to load in some libraries, feel free to download these if you’ve yet to do so.\n# Loading in libraries\nlibrary (jsonlite)\nlibrary (spotifyr)\nlibrary (tidyverse)\nThen load in your API tokens that you’ve set up in your system environment above.\naccess_token &lt;- get_spotify_access_token()\nThe data you get from R comes in two sets (if you’ve requested both files). The first set is just your streaming history from your last 30 days and the second is your extended streaming history. This first section below will go through the former file.\n\n\n\nLast 30 days of streaming\nRead in the streaming histories and concatenate it all into one long list\n## Read in streaming histories\nstr_hist0 &lt;- read_json (\"./MyData/StreamingHistory0.json\")\nstr_hist1 &lt;- read_json (\"./MyData/StreamingHistory1.json\")\nstr_hist2 &lt;- read_json (\"./MyData/StreamingHistory2.json\")\nstr_hist3 &lt;- read_json (\"./MyData/StreamingHistory3.json\")\n\n## Concatenate \nstr_hist_all &lt;- append (str_hist0, str_hist1)\nstr_hist_all &lt;- append (str_hist_all, str_hist2)\nstr_hist_all &lt;- append (str_hist_all, str_hist3)\nOnce done, collapse it into a dataframe so it’s more user friendly\n## Convert to dataframe of tracknames, dates and artist\nstr_hist_all_trkdate = NULL\nfor (i in 1:length (str_hist_all)) {\n  track &lt;- str_hist_all[[i]][[\"trackName\"]]\n  date &lt;- str_hist_all[[i]][[\"endTime\"]]\n  artist &lt;- str_hist_all[[i]][[\"artistName\"]]\n  str_hist_all_trkdate &lt;- as.data.frame (rbind (str_hist_all_trkdate, cbind (track, date, artist)))\n}\n\nstr_hist_all_trkdate &lt;- unique (str_hist_all_trkdate)\nTo access their database, Spotify uses Unique IDs (UID). This ID isn’t stored in the dataset they give you, and instead you would have to search it up. Luckily the package ‘spotifyr’ makes this whole ordeal somewhat less painful. Here, I’m searching it up by Artist ID as Spotify appends genres to the artist rather than the song.\n## Get UID of artists\n\nstr_hist_all_artists &lt;- unique (str_hist_all_trkdate$artist)\n\n### The below tries different methods to extract the UID per artist. The final output is a dataframe that links artists to their UID. If no UID is found for the artists, they are likely a podcast/show.\nartist_list = NULL\nfor (i in 1:lartist_list = NULL\nfor (i in 1:length (str_hist_all_artists)){\n  print (paste (\"Running\", i, \"out of\", length(str_hist_all_artists)))\n  if (exists (\"artist\")) {remove (artist)}\n  if (exists (\"artist_ID\")) {remove (artist_ID)}\n  artist_info = NA\n  artist &lt;- str_hist_all_artists[i]\n  artist_search &lt;- search_spotify (artist, type = \"artist\")\n  if ( nrow (artist_search) != 0 ) {for (j in 1:nrow (artist_search)) {\n    if (artist_search[j,5] == artist) {\n      artist_ID &lt;- as.character (artist_search[j,3])}}}\n  \n  if (exists (\"artist_ID\") == TRUE) {\n    if (tryCatch ({get_artist (artist_ID)$name == artist}, error = function(e) {FALSE})){\n      artist_list &lt;- as.data.frame (rbind (artist_list, cbind (artist, artist_ID)))\n      } else {\n        artist_ID = NA\n        artist_list &lt;- as.data.frame (rbind (artist_list, cbind (artist, artist_ID)))}}\n  \n  if (exists (\"artist_ID\") == FALSE) {\n    tryCatch({\n      artist_info &lt;- get_artist_audio_features (artist)\n    }, error = function(e) {\n      artist_info &lt;- get_artist_audio_features (artist, include_groups = \"single\")\n    }, error = function(e2) {artist_info = NA})\n    if (exists (\"artist_info\") == TRUE) {\n      artist_ID &lt;- tryCatch (artist_info$artist_id[1], error = function(e) {\n        artist_info$artist_id[2]\n      }, error = function(e2) {\n        if (!exists (\"artist_ID\")) {artist_ID &lt;- NA}})}\n    if (exists (\"artist_ID\") == TRUE) {\n      if (tryCatch ({get_artist (artist_ID)$name == artist}, error = function(e) {FALSE})){\n        artist_list &lt;- as.data.frame (rbind (artist_list, cbind (artist, artist_ID)))\n        } else {\n          artist_ID = NA\n          artist_list &lt;- as.data.frame (rbind (artist_list, cbind (artist, artist_ID)))}}}}\nNow with the artist IDs we can search up their genres and join them into our dataset\n## Get genres of artists\nartist_list_filt &lt;- artist_list %&gt;% filter (!is.na (artist_ID)) # Removing shows/episodes\n\nartist_genre = NULL\ngenre_list = NULL\nfor (id in 1:nrow (artist_list_filt)){\n  print (paste (\"Running\", id, \"out of\", nrow (artist_list_filt)))\n  artist_ID &lt;- artist_list_filt[id,2]\n  info &lt;- get_artist (artist_ID)\n  genres &lt;- info$genres\n  genres_concat &lt;- paste (info$genres, collapse=', ')\n  genre_list &lt;- append (genre_list, genres)\n  artist_genre &lt;- as.data.frame (rbind (artist_genre, cbind (artist_ID, genres_concat)))\n}\n\ngenre_list &lt;- unlist (genre_list)\nartist_list_filt_genre &lt;- left_join (artist_list_filt, artist_genre)\nIt is an understatement to say that there are a lot of miscellaneous genres in Spotify. For example, each tiny sliver in this pie chart below represent a single genre.\n## Merging artist UID to track list\nstr_hist_artists &lt;- left_join (str_hist_all_trkdate, artist_list_filt_genre, by = 'artist')\n\n## There are way too many genres in Spotify... here's how many\ngenre_df &lt;- as.data.frame (genre_list)\ngenre_summ &lt;- genre_df %&gt;% group_by (genre_list) %&gt;% summarise (n = n())\n\ntop_10_genre_summ &lt;- genre_summ %&gt;% # Gathering the top 10 genres\n  arrange (desc(n)) %&gt;%\n  head (10)\n\nggplot (genre_summ, aes (x = \"\", y = n, fill = genre_list)) +\n  geom_bar (stat = \"identity\", width = 0.01, color = \"white\") +\n  coord_polar (\"y\", start = 0,) +\n  theme_void () +\n  theme (legend.position = \"none\") +\n  labs (title = \"Number of occurrences of each genre\", caption = \"Theres 379 genres in just my streaming history of the last 30 days\") +\n  theme (text = element_text (size = 50), plot.title = element_text (hjust = 0.5))\n\n\n\n\n\nSo to properly investigate genres I’ve chosen to merge a few of the genres together. The order of the merging may lead to bias (e.g., indie pop), but what can yah do.\nstr_hist_artists_genre_merge &lt;- as.data.frame (unique (str_hist_artists$genres))\n\nmerge_list = NULL\nfor (i in 1:nrow (str_hist_artists_genre_merge)) {\n  merge = str_hist_artists_genre_merge[i,1]\n  if(grepl (\"alt z\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"alt z\"}\n  if(grepl (\"indie\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"indie\"}\n  if(grepl (\"pop\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"pop\"}\n  if(grepl (\"folk\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"folk\"}\n  if(grepl (\"rock\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"rock\"}\n  if(grepl (\"rap\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"rap\"}\n  if(grepl (\"jazz\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"jazz\"}\n  if(grepl (\"metal\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"metal\"}\n  if(grepl (\"lo-fi\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"lo-fi\"}\n  if(grepl (\"r&b\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"r&b\"}\n  if(grepl (\"stomp and holler\", str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"stomp and holler\"}\n  merge_list &lt;- append (merge_list, merge)\n}\n\nmerge_dict &lt;- cbind (str_hist_artists_genre_merge[1], merge_list)\ncolnames (merge_dict)[1] &lt;- \"genres_concat\"\n\n## Merging genres by original genre name\nstr_hist_artists_merged &lt;- left_join (str_hist_artists, merge_dict, by = \"genres_concat\")\nNow let’s look at some plots!\n\nTop 100 songs\nWhat are the top 100 songs in my streaming history of the last 30 days?\nFirst we make a frequency table to find how many time each song was played. This lets me find the top 100 which I can use to generate the plot\n## Frequency table and plot\ntrack_freq &lt;- str_hist_artists_merged %&gt;% filter (!is.na (artist_ID)) %&gt;% group_by (track) %&gt;% summarise (n = n())\nartists_merged_info &lt;- str_hist_artists_merged %&gt;% filter (!is.na (artist_ID)) %&gt;%  select (track, artist, artist_ID, merge_list)\n\ntrack_freq_merged &lt;- left_join (track_freq, artists_merged_info, by = \"track\", multiple = \"first\")\ntrack_freq_sort &lt;- track_freq_merged[order (track_freq_merged$n, decreasing = TRUE), ]\ntrack_freq_top100 &lt;- track_freq_sort[1:100,] # Top 100\n\ntrack_freq_top100$track &lt;- factor (track_freq_top100$track, levels = track_freq_sort$track) # Converting to factor to preserve order\n\nggplot (track_freq_top100, aes(x = track, y = n, fill = merge_list)) +\n  geom_bar (stat = \"identity\") + \n  geom_text (aes (label = n), size = 2.5, nudge_y = 2) +\n  theme (axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs (title = \"Top 100 songs in last 30 days streaming history\", y = \"Count\", fill = \"Genres\", x = \"Song name\")\nP.S. Click on the image to zoom in!\n\n\n\n\n\n\n\nTop genres\nRepeating a similar analysis but with my genres now\ngenre_freq &lt;- artists_merged_info %&gt;% group_by (merge_list) %&gt;% summarise (n = n())\ngenre_freq_sort &lt;- genre_freq [order (genre_freq$n, decreasing = TRUE), ]\ngenre_freq_sort &lt;- genre_freq_sort [1:50, ]\ngenre_freq_sort$merge_list &lt;- factor (genre_freq_sort$merge_list, levels = genre_freq_sort$merge_list) # Converting to factor to preserve order\n\nggplot (genre_freq_sort, aes (x = merge_list, y = n, fill = merge_list)) +\n  geom_bar (stat = \"identity\") + \n  geom_text (aes (label = n), size = 2.5, nudge_y = 100) +\n  theme (axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\") +\n  labs (title = \"Top 50 genres in last 30 days streaming history\", y = \"Count\", x = \"Genre\")\n\n\n\n\n\n\n\nTop artists\nAnd my top 100 artists…\nartist_freq &lt;- artists_merged_info %&gt;% group_by (artist) %&gt;% summarise (n=n())\nartist_freq_sort &lt;- artist_freq [order (artist_freq$n, decreasing = TRUE), ]\nartist_freq_sort_top100 &lt;- artist_freq_sort [1:100,] # Top 100\nartist_freq_sort_top100$artist &lt;- factor (artist_freq_sort_top100$artist, levels = artist_freq_sort_top100$artist) # Converting to factor to preserve order\n\nggplot (artist_freq_sort_top100, aes(x = artist, y = n, fill = artist)) +\n  geom_bar (stat = \"identity\") + \n  geom_text (aes (label = n), size = 2.5, nudge_y = 10) +\n  theme (axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\") +\n  labs (title = \"Top 100 artists in last 30 days streaming history\", x = \"Artists\", y = \"Count\")\n\n\n\n\n\n\n\n\n\nAll time streaming\nNow some may think that’s good enough to fill in the blank spot of when someone asks me “What’s your favourite song”. But what if they ask me “What’s your favourite song of all time”. Well, I guess the best I got for them is analysing my whole Spotify streaming history. Sorry kind person but that’s the best you’ll get out of me. I guess they’ll never be able to find out about my Britney addiction I had in primary school…\nThe set up and workflow is very similar to the one above. First we load in the data, append it all together, then collapse it.\n# Processing the full streaming history\nextended_str_hist0 &lt;- read_json (\"./MyData/Streaming_History_Audio_2020-2021_0.json\")\nextended_str_hist1 &lt;- read_json (\"./MyData/Streaming_History_Audio_2021-2022_1.json\")\nextended_str_hist2 &lt;- read_json (\"./MyData/Streaming_History_Audio_2022_2.json\")\nextended_str_hist3 &lt;- read_json (\"./MyData/Streaming_History_Audio_2022-2023_3.json\")\nextended_str_hist4 &lt;- read_json (\"./MyData/Streaming_History_Audio_2023_4.json\")\n\nextended_str_hist_all &lt;- append (extended_str_hist0, extended_str_hist1)\nextended_str_hist_all &lt;- append (extended_str_hist_all, extended_str_hist2)\nextended_str_hist_all &lt;- append (extended_str_hist_all, extended_str_hist3)\nextended_str_hist_all &lt;- append (extended_str_hist_all, extended_str_hist4)\n\nextended_str_hist_all_trkdate = NULL\nfor (i in 1:length (extended_str_hist_all)) {\n  print (paste (\"Running\", i, \"out of\", length(extended_str_hist_all)))\n  track &lt;- extended_str_hist_all[[i]][[\"master_metadata_track_name\"]]\n  date &lt;- extended_str_hist_all[[i]][[\"ts\"]]\n  artist &lt;- extended_str_hist_all[[i]][[\"master_metadata_album_artist_name\"]]\n  length &lt;- extended_str_hist_all[[i]][[\"ms_played\"]]\n  if (is.null (track) == TRUE | is.null (artist) == TRUE) {next}\n  extended_str_hist_all_trkdate &lt;- as.data.frame (rbind (extended_str_hist_all_trkdate, cbind (track, date, artist, length)))}\nAnd we get the artist UID…\n## Get UID of artists\n\nextended_str_hist_all_artists &lt;- unique (extended_str_hist_all_trkdate$artist)\n\n### The below tries different methods to extract the UID per artist. The final output is a dataframe that links artists to their UID. If no UID is found for the artists, they are likely a podcast/show.\nextended_artist_list = NULL\nfor (i in 1:length (extended_str_hist_all_artists)){\n  print(paste (\"Running\", i, \"out of\", length (extended_str_hist_all_artists)))\n  if (exists (\"artist\")) {remove (artist)}\n  if (exists (\"artist_ID\")) {remove (artist_ID)}\n  artist_info = NA\n  artist &lt;- extended_str_hist_all_artists[i]\n  print (artist)\n  artist_search &lt;- search_spotify (artist, type = \"artist\")\n  if (nrow (artist_search) != 0 ) {for (j in 1:nrow (artist_search)) {\n    if (artist_search[j,5] == artist) {\n      artist_ID &lt;- as.character (artist_search[j,3])}}}\n  \n  if (exists (\"artist_ID\") == TRUE) {\n    if (tryCatch ({get_artist (artist_ID)$name == artist}, error = function(e) {FALSE})){\n      extended_artist_list &lt;- as.data.frame (rbind (extended_artist_list, cbind (artist, artist_ID)))\n      } else {\n        artist_ID = NA\n        extended_artist_list &lt;- as.data.frame (rbind (extended_artist_list, cbind (artist, artist_ID)))}}\n  \n  if (exists (\"artist_ID\") == FALSE) {\n    tryCatch({\n      artist_info &lt;- get_artist_audio_features (artist)\n    }, error = function(e) {\n      artist_info &lt;- get_artist_audio_features (artist, include_groups = \"single\")\n    }, error = function(e2) {artist_info = NA})\n    if (exists (\"artist_info\") == TRUE) {\n      artist_ID &lt;- tryCatch (artist_info$artist_id[1], error = function(e) {\n        artist_info$artist_id[2]\n      }, error = function(e2) {\n        if (!exists (\"artist_ID\")) {artist_ID &lt;- NA}})}\n    \n    if (exists (\"artist_ID\") == TRUE) {\n      if (tryCatch ({get_artist (artist_ID)$name == artist}, error = function(e) {FALSE})){\n        extended_artist_list &lt;- as.data.frame (rbind (extended_artist_list, cbind (artist, artist_ID)))\n        } else {\n          artist_ID = NA\n          extended_artist_list &lt;- as.data.frame (rbind (extended_artist_list, cbind (artist, artist_ID)))}}}}\n… And their genres.\n## Get genres of artists\nextended_artist_list_filt &lt;- extended_artist_list %&gt;% filter (!is.na (artist_ID)) # Removing shows/episodes\n\nextended_artist_genre = NULL\nextended_genre_list = NULL\nfor (id in 1:nrow (extended_artist_list_filt)){\n  print (paste (\"Running\", id, \"out of\", nrow (extended_artist_list_filt)))\n  artist_ID &lt;- extended_artist_list_filt[id,2]\n  info &lt;- get_artist (artist_ID)\n  genres &lt;- info$genres\n  genres_concat &lt;- paste (info$genres, collapse=', ')\n  extended_genre_list &lt;- append (genre_list, genres)\n  extended_artist_genre &lt;- as.data.frame (rbind (extended_artist_genre, cbind (artist_ID, genres_concat)))\n}\n\nextended_genre_list &lt;- unlist (extended_genre_list)\nextended_artist_list_filt_genre &lt;- left_join (extended_artist_list_filt, extended_artist_genre, multiple = \"first\")\nAnd then we merge the genres together\n## Merging artist UID to track list\nextended_str_hist_artists &lt;- unique (left_join (extended_str_hist_all_trkdate, extended_artist_list_filt_genre, by = 'artist'))\n\n## Let's merge a couple of genres together, the order of the merging may lead to bias (e.g., indie pop), but what can yah do\nextended_genre_df &lt;- as.data.frame (extended_genre_list)\nextended_genre_summ &lt;- extended_genre_df %&gt;% group_by (extended_genre_list) %&gt;% summarise (n = n())\n\nextended_top_10_genre_summ &lt;- extended_genre_summ %&gt;% # Gathering the top 10 genres\n  arrange (desc (n)) %&gt;%\n  head (10)\n\nextended_str_hist_artists_genre_merge &lt;- as.data.frame(unique(extended_str_hist_artists$genres))\n\nextended_merge_list = NULL\nfor (i in 1:nrow (extended_str_hist_artists_genre_merge)) {\n  merge = extended_str_hist_artists_genre_merge[i,1]\n  if (grepl (\"alt z\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"alt z\"}\n  if (grepl (\"indie\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"indie\"}\n  if (grepl (\"pop\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"pop\"}\n  if (grepl (\"folk\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"folk\"}\n  if (grepl (\"rock\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"rock\"}\n  if (grepl (\"rap\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"rap\"}\n  if(grepl (\"jazz\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"jazz\"}\n  if (grepl (\"metal\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"metal\"}\n  if (grepl (\"lo-fi\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"lo-fi\"}\n  if (grepl (\"r&b\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"r&b\"}\n  if (grepl (\"stomp and holler\", extended_str_hist_artists_genre_merge[i,1], ignore.case = TRUE)) {merge = \"stomp and holler\"}\n  extended_merge_list &lt;- append (extended_merge_list, merge)\n}\nextended_merge_dict &lt;- cbind (extended_str_hist_artists_genre_merge[1], extended_merge_list)\ncolnames (extended_merge_dict)[1] &lt;- \"genres_concat\"\nextended_str_hist_artists_merged &lt;- left_join (extended_str_hist_artists, extended_merge_dict, by = \"genres_concat\") %&gt;% \n  select (!genres_concat)\n\nTop 100 songs\nNow for some plots! My top 100 songs of all time\n## Frequency table and plot\nextended_track_freq &lt;- extended_str_hist_artists_merged %&gt;% filter (!is.na (artist_ID)) %&gt;% group_by (track) %&gt;% summarise (n = n())\nextended_artists_merged_info &lt;- extended_str_hist_artists_merged %&gt;% filter (!is.na(artist_ID)) %&gt;%  select (track, artist, artist_ID, extended_merge_list)\n\nextended_track_freq_merged &lt;- left_join (extended_track_freq, extended_artists_merged_info, by = \"track\", multiple = \"first\")\nextended_track_freq_sort &lt;- extended_track_freq_merged [order(extended_track_freq_merged$n, decreasing = TRUE), ]\nextended_track_freq_top100 &lt;- extended_track_freq_sort[1:100,] # Top 100\n\nextended_track_freq_top100$track &lt;- factor (extended_track_freq_top100$track, levels = extended_track_freq_sort$track) # Converting to factor to preserve order\n\nggplot (extended_track_freq_top100, aes(x = track, y = n, fill = extended_merge_list)) +\n  geom_bar (stat = \"identity\", width = 0.9) + \n  geom_text (aes (label = n), size = 2.5, nudge_y = 3) +\n  theme (axis.text.x = element_text (angle = 45, hjust = 1)) +\n  labs (fill = \"Genres\", title = \"Top 100 songs in all streaming history\", y = \"Count\", x = \"Track\")\n\n\n\n\n\n\n\nTop genres\nextended_genre_freq &lt;- extended_artists_merged_info %&gt;% group_by (extended_merge_list) %&gt;% summarise (n = n())\nextended_genre_freq_sort &lt;- extended_genre_freq [order (extended_genre_freq$n, decreasing = TRUE), ]\nextended_genre_freq_sort &lt;- extended_genre_freq_sort[1:50,]\nextended_genre_freq_sort$merge_list &lt;- factor (extended_genre_freq_sort$extended_merge_list, levels = extended_genre_freq_sort$extended_merge_list) # Converting to factor to preserve order\n\nggplot (extended_genre_freq_sort, aes (x = merge_list, y = n, fill = merge_list)) +\n  geom_bar (stat = \"identity\") + \n  geom_text (aes (label = n), size = 3, nudge_y = 300) +\n  theme (axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\") +\n  labs (x = \"Genres\", y = \"Count\", title = \"Top 100 genres in all streaming history\")\n\n\n\n\n\n\n\nTop artists\nextended_artist_freq &lt;- extended_artists_merged_info %&gt;% group_by (artist) %&gt;% summarise (n = n())\nextended_artist_freq_sort &lt;- extended_artist_freq [order (extended_artist_freq$n, decreasing = TRUE), ]\nextended_artist_freq_sort_top100 &lt;- extended_artist_freq_sort [1:100,] # Top 100\nextended_artist_freq_sort_top100$artist &lt;- factor (extended_artist_freq_sort_top100$artist, levels = extended_artist_freq_sort_top100$artist) # Converting to factor to preserve order\n\nggplot (extended_artist_freq_sort_top100, aes (x = artist, y = n, fill = artist)) +\n  geom_bar (stat = \"identity\") + \n  geom_text (aes (label = n), size = 3, nudge_y = 10) +\n  theme (axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\") +\n  labs (x = \"Artists\", y = \"Count\", title = \"Top 100 artists in all streaming history\")\n\n\n\n\n\n\n\nTop 10 artist’s hours listened\nAnd finally, how many hours of the Top 10 artists do I listen to\nextended_artist_freq_sort_top10 &lt;- extended_artist_freq_sort [1:10,] # Top 10\nextended_str_hist_all_trkdate$length &lt;- as.numeric (extended_str_hist_all_trkdate$length)\nextended_top10_time &lt;- extended_str_hist_all_trkdate %&gt;% \n  filter (artist %in% extended_artist_freq_sort_top10$artist) %&gt;% \n  group_by (artist) %&gt;% \n  summarise (total_length = sum (length)) %&gt;% \n  mutate(total_length_hours = total_length/1000/60/60)\n\nggplot(extended_top10_time, aes (x = artist, y = total_length_hours, fill = artist)) +\n  geom_bar (stat = \"identity\", width = 0.7) + \n  theme (legend.position = \"none\") +\n  labs (x = \"Artists\", y = \"Hours listened\", title = \"Hours listened of top 10 artists\")\n\n\n\n\n\n\n\n\n\n\nConclusion\nHow socially appropriate is it to just give someone this link if they ask me this question. I know for sure I’m already going to give it to one person regardless (hello!).\nTldr; Indie pop?"
  },
  {
    "objectID": "posts/spotify/index.html#section",
    "href": "posts/spotify/index.html#section",
    "title": "So, what music do you like?",
    "section": "————————————————————————",
    "text": "————————————————————————"
  },
  {
    "objectID": "posts/ESA/index.html",
    "href": "posts/ESA/index.html",
    "title": "ESA 2023",
    "section": "",
    "text": "Everytime I go to a conference I’m always amazed at the wide diversity of both people and work that’s being done in ecology. It’s both a humbling and inspiring moment for me.\nAt ESA2023 I was given the opportunity to talk about the project I’d been working on at the Research Centre for Ecosystem Resilience at the Botanic Gardens of Sydney. The number of people that came up to talk about the work, and to tell me that my talk went well was heart touching.\n\n\n\nThanks for having me and helping us spread the word about restore and renew to those who need it! #ESAus23 @EcolSocAus pic.twitter.com/xn9YxM2emK\n\n— Karina Guo (she/her) (@dandy_gumnut) July 5, 2023\n\n\n\nI’ll always be grateful for the networking that was made possible by such events. I’ve met people I never thought I would come into contact with. People who have been in the field for decades, to people who are just like me. Regardless, of their ages they’ve become a familiar face in this sea of unknown. Conversations with them, (gifts even!), will be something I cherish for long.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDarwin at night\n\n\n\n\n\n\n\nDarwin's sunrise\n\n\n\n\n\n\n\nA new friend, a kind gentleman\n\n\n\n\n\n\n\nTalks at ESA\n\n\n\n\n\n\n\nConference hall\n\n\n\n\n\n\n\nConference dinner\n\n\n\n\n\nPrevoius\n\n\n\nNext\n\n\n\n\nOther than that, wow Darwin offered so many beautiful sunsets and sunrises. The number of beaches in a walkable distance was definitely appreciated. Going for a morning run to visit a new beach each morning was amazing for my mental health (and probably physical with how much I ate, I still can’t say no to free food). I’m glad I even had time to go bird spotting even with my busy schedule, they were absolutely gorgeous with their colourful plumes."
  },
  {
    "objectID": "posts/ESA/index.html#conference-ecological-society-of-australia-2023",
    "href": "posts/ESA/index.html#conference-ecological-society-of-australia-2023",
    "title": "ESA 2023",
    "section": "",
    "text": "Everytime I go to a conference I’m always amazed at the wide diversity of both people and work that’s being done in ecology. It’s both a humbling and inspiring moment for me.\nAt ESA2023 I was given the opportunity to talk about the project I’d been working on at the Research Centre for Ecosystem Resilience at the Botanic Gardens of Sydney. The number of people that came up to talk about the work, and to tell me that my talk went well was heart touching.\n\n\n\nThanks for having me and helping us spread the word about restore and renew to those who need it! #ESAus23 @EcolSocAus pic.twitter.com/xn9YxM2emK\n\n— Karina Guo (she/her) (@dandy_gumnut) July 5, 2023\n\n\n\nI’ll always be grateful for the networking that was made possible by such events. I’ve met people I never thought I would come into contact with. People who have been in the field for decades, to people who are just like me. Regardless, of their ages they’ve become a familiar face in this sea of unknown. Conversations with them, (gifts even!), will be something I cherish for long.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDarwin at night\n\n\n\n\n\n\n\nDarwin's sunrise\n\n\n\n\n\n\n\nA new friend, a kind gentleman\n\n\n\n\n\n\n\nTalks at ESA\n\n\n\n\n\n\n\nConference hall\n\n\n\n\n\n\n\nConference dinner\n\n\n\n\n\nPrevoius\n\n\n\nNext\n\n\n\n\nOther than that, wow Darwin offered so many beautiful sunsets and sunrises. The number of beaches in a walkable distance was definitely appreciated. Going for a morning run to visit a new beach each morning was amazing for my mental health (and probably physical with how much I ate, I still can’t say no to free food). I’m glad I even had time to go bird spotting even with my busy schedule, they were absolutely gorgeous with their colourful plumes."
  }
]